# -*- coding: utf-8 -*-
"""Emotion Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BmPoEkFhXvbg5nJVgZ571aothcSwS49O
"""

!pip install pandas scikit-learn nltk

import pandas as pd

# Step 1: Define a function to load the .txt files
def load_emotion_file(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        lines = [line.strip().split(";") for line in f if ";" in line]
    return pd.DataFrame(lines, columns=["text", "label"])

# Step 2: Load all 3 datasets
train_df = load_emotion_file("train.txt")
val_df = load_emotion_file("val.txt")
test_df = load_emotion_file("test.txt")

# Step 3: Combine train and validation for training
full_train_df = pd.concat([train_df, val_df], ignore_index=True)

# Step 4: Clean the text (optional but improves results)
import re
def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z\s]", "", text)
    return text

full_train_df["text"] = full_train_df["text"].apply(clean_text)
test_df["text"] = test_df["text"].apply(clean_text)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score

# Encode labels
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(full_train_df["label"])
y_test = label_encoder.transform(test_df["label"])

# Build and train the model
model_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('clf', LogisticRegression(max_iter=1000))
])

model_pipeline.fit(full_train_df["text"], y_train)

# Evaluate
y_pred = model_pipeline.predict(test_df["text"])
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))